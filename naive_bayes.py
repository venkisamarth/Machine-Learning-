# -*- coding: utf-8 -*-
"""Naive Bayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-wAPX3gkN5c1Y20o7EuDeTeWx8OQQ47W

IRIS DATA SET AND EDA
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.naive_bayes import GaussianNB
from sklearn.datasets import load_iris

#Lode the data Iris dataset
iris=load_iris()
iris_df=pd.DataFrame(data=iris.data, columns=iris.feature_names)
iris_df['target']=iris.target

#print the first 5 rows of the dataset 
iris_df.head()

#get the mean median of the standard deviation for te each feature
iris_df.describe().T

#Get the number of observation from the each class
iris_df['target'].value_counts()

#plot histograms for each feature
iris_df.hist(bins=20,figsize=(10,8))
plt.show()

#plot box plots for each feature 
iris_df.plot(kind='box',  subplots=True, layout=(3,3), sharex=False, sharey=False, figsize=(10 , 8))
plt.show()

#plot pair plot
import seaborn as sns
sns.pairplot(iris_df ,hue='target')
plt.show()

"""Naive bayes classifier algorithm Example"""

from sklearn.naive_bayes import GaussianNB
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Initialize the Gaussian Naive Bayes classifier
gnb = GaussianNB()

#Initialize the gassioan Naive Bayes classifier
gnb=GaussianNB()

#Trian the calassifier on the trining data
gnb.fit(x_train,y_train)

# Train the classifier on the training data
gnb.fit(X_train, y_train)

# Make predictions on the test data
y_pred = gnb.predict(X_test)

# Print the accuracy of the classifier
print("Accuracy:", gnb.score(X_test, y_test))

"""Validation matrix for callsificaton model"""

from  sklearn.metrics import confusion_matrix, precision_score,recall_score,f1_score

from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

# Generate the confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix: \n", cm)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print("Precision: ", precision)
print("Recall: ", recall)
print("F1-score: ", f1)

"""Roc Curve for multiclass"""

from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# Get the probability predictions for the test set
y_prob = gnb.predict_proba(X_test)

# Get the false positive rate (fpr), true positive rate (tpr) and thresholds for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
num_classes = 3

# For each class, calculate the ROC curve and AUC

for i in range(num_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test == i, y_prob[:, i])
    roc_auc[i] = roc_auc_score(y_test == i, y_prob[:, i])

# Plot the ROC curves for each class
for i in range(num_classes):
    plt.plot(fpr[i], tpr[i], label='Class %d AUC = %0.2f' % (i, roc_auc[i]))

# Plot the random classifier line
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Multi-class ROC Curve')
plt.legend(loc="lower right")
plt.show()

"""Model serilizalion or Deployment"""

import pickle

# Serialize the model object
with open('naive_bayes_model.pkl', 'wb') as f:
    pickle.dump(gnb, f)

# Deserialize the model object
with open('naive_bayes_model.pkl', 'rb') as f:
    gnb_loaded = pickle.load(f)
    
    
# Use the loaded model to make predictions on new data
y_pred = gnb_loaded.predict(X_test)
print(y_pred)